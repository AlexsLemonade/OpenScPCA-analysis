---
title: "Comparison among doublet predictions on benchmarking datasets"
author: Stephanie J. Spielman
date: "`r Sys.Date()`"
output: 
  html_notebook:
    toc: true
    toc_depth: 4
    code_folding: hide
---

This notebook compares doublet results calculated on benchmarking datasets to one another, with the primary goal of addressing these questions:

1. Do methods tend to predict overlapping or distinct sets of doublets on the same dataset?
2. Is the consensus doublet call across methods predictive of the true doublet status?
Here, the "consensus doublets" are those droplets which all methods identify as doublets.

There are several items to bear in mind when interpreting these results:

- The ground truth calls themselves to which we are comparing consensus calls may not be entirely accurate, since they were also computationally identified generally with demultiplexing algorithms. 
- `cxds`, as we are using it, does not have a specific threshold for calling droplets. 
By contrast, both `scrublet` and `scDblFinder` identify a threshold based on the given dataset they are processing. 
This notebook uses a doublet threshold of `>=0.5` for `cxds`, which may not be universally suitable (though choosing a universally suitable threshold is not easy either!).

## Setup

### Packages


```{r packages}
suppressPackageStartupMessages({
  library(SingleCellExperiment)
  library(ggplot2)
  library(patchwork)
  library(caret)
  library(UpSetR)
})

theme_set(theme_bw())

# define threshold used to call cxds
cxds_threshold <- 0.5
```

### Paths


```{r base paths}
module_base <- rprojroot::find_root(rprojroot::is_renv_project)
data_dir <- file.path(module_base, "scratch", "benchmark-datasets")
result_dir <- file.path(module_base, "results", "benchmark-results")
```

### Functions

```{r}
plot_pca_calls <- function(df, 
                           color_column, 
                           pred_column,
                           title) {
  # Plot PCs colored by singlet/doublet, showing doublets on top
  # df is expected to contain columns PC1, PC2, `color_column`, and `pred_column`. These should _not_ be provided as strings
  ggplot(df) + 
    aes(x = PC1, 
        y = PC2, 
        color = {{color_column}}) +
  geom_point(
    size = 0.75, 
    alpha = 0.6
  ) +
  scale_color_manual(name = "", values = c("black", "gray80")) + 
  geom_point(
    data = dplyr::filter(df, {{color_column}} == "doublet"), 
    color = "black",
    size = 0.75
  ) +
  ggtitle(title) 
}

plot_pca_metrics <- function(df, color_column, metric_colors) {
  # Plot PCs colored by performance metric, showing false calls on top
  # metric_colors is a named vector of colors used for coloring tp/tn/fp/fn
  # df is expected to contain columns PC1, PC2, and `color_column`. This should _not_ be provided as a string.
  ggplot(df) + 
    aes(x = PC1, 
        y = PC2, 
        color = {{color_column}}) +
  geom_point(
    size = 0.75, 
    alpha = 0.6
  ) + 
  geom_point(
    data = dplyr::filter(df, {{color_column}} %in% c("fp", "fn")), 
    size = 0.75
  ) +
  scale_color_manual(name = "Call type", values = metric_colors) +
  ggtitle("Consensus class metrics")
}
```


## Read and prepare input data

First, we'll read in and combine doublet results into a list of data frames for each dataset.
We'll also create new columns for each dataset:

- `consensus_class`, which will be "doublet" if all three methods are doublet, "singlet" if all three methods are singlet, and "ambiguous" if there are any disagreements
- `consensus_call`, which will be "doublet" if _all_ methods predict "doublet," and "singlet" otherwise
- `confusion_call`, which will classify the consensus call as one of "tp", "tn", "fp", or "fn" (true/false positive/negative) based on `consensus_call`

      
      

```{r paths}
# find all dataset names to process:
dataset_names <- list.files(result_dir, pattern = "*_scrublet.tsv") |>
  stringr::str_remove("_scrublet.tsv")
```

```{r read_data}
# used in PCA plots
confusion_colors <- c(
  "tp" = "lightblue",
  "tn" = "pink",
  "fp" = "blue",
  "fn" = "firebrick2"
)

# Read in data for analysis
doublet_df_list <- dataset_names |>
  purrr::map(
    \(dataset) {
      
      scdbl_tsv <- file.path(result_dir, glue::glue("{dataset}_scdblfinder.tsv"))
      scrub_tsv <- file.path(result_dir, glue::glue("{dataset}_scrublet.tsv"))
      sce_file <- file.path(data_dir, dataset, glue::glue("{dataset}_sce.rds"))
      
      scdbl_df <- scdbl_tsv |>
        readr::read_tsv(show_col_types = FALSE) |>
        dplyr::select(
          barcodes,
          cxds_score, 
          scdbl_score = score, 
          scdbl_prediction  = class
        ) |>
        # add cxds calls at `cxds_threshold` threshold
        dplyr::mutate(
          cxds_prediction = dplyr::if_else(
            cxds_score >= cxds_threshold,
            "doublet",
            "singlet"
          )
        ) 
      
      scrub_df <- readr::read_tsv(scrub_tsv, show_col_types = FALSE) 

      # grab ground truth and PCA coordinates
      sce <- readr::read_rds(sce_file)
      dataset_df <- scuttle::makePerCellDF(sce, use.dimred = "PCA") |>
        tibble::rownames_to_column(var = "barcodes") |>
        dplyr::select(barcodes,
                      ground_truth = ground_truth_doublets, 
                      PC1 = PCA.1, 
                      PC2 = PCA.2) |> 
        dplyr::left_join(
          scrub_df, 
          by = "barcodes"
        ) |>
        dplyr::left_join(
          scdbl_df, 
          by = "barcodes"
        ) 
      
      # Add consensus columns:
      # - consensus_class: "doublet" if all three methods are doublet, "singlet" if all three methods are singlet, 
      #    and "ambiguous" if there are any disagreements
      # - consensus_call: "doublet" if all three methods are doublet, and "singlet" otherwise
      # - confusion_call: tp/tn/fp/fn based on the `consensus_call` column
      dataset_df <- dataset_df |>
        dplyr::rowwise() |>
        # Add column `consensus_call`
        dplyr::mutate(
          consensus_call = dplyr::if_else(
            all(c(scdbl_prediction, scrublet_prediction, cxds_prediction) == "doublet"),
            "doublet", 
            "singlet"
          )
        ) |>
        # Add column `consensus_class`
        dplyr::mutate(
          consensus_class = dplyr::case_when(
            consensus_call == "doublet" ~ "doublet",
            all(c(scdbl_prediction, scrublet_prediction, cxds_prediction) == "singlet") ~ "singlet", 
            .default = "ambiguous"
          )
         ) |>
        # Add column `confusion_call`
        dplyr::mutate(
          confusion_call = dplyr::case_when(
            consensus_call == "doublet" && ground_truth == "doublet" ~ "tp",
            consensus_call == "singlet" && ground_truth == "singlet" ~ "tn",
            consensus_call == "doublet" && ground_truth == "singlet" ~ "fp",
            consensus_call == "singlet" && ground_truth == "doublet" ~ "fn"
          )
        )
      
      return(dataset_df)
    }
  ) |> 
  purrr::set_names(dataset_names)
```




## Upset plots

This section contains upset plots that show overlap across doublet calls from each method, displayed for each dataset.

```{r}
upset_list <- doublet_df_list |>
  purrr::iwalk(
    \(df, dataset) {
      
      doublet_barcodes <- list(
        "scDblFinder" = df$barcodes[df$scdbl_prediction == "doublet"],
        "scrublet"    = df$barcodes[df$scrublet_prediction == "doublet"],
        "cxds"        = df$barcodes[df$cxds_prediction == "doublet"]
      )
      
      UpSetR::upset(fromList(doublet_barcodes), order.by = "freq") |> print()
      grid::grid.text( # plot title
        dataset,
        x = 0.65, 
        y = 0.95, 
        gp = grid::gpar(fontsize=16)
      ) 

    }
  )

```



## Evaluating consensus performance

This section visualizes and evaluates the consensus doublet calls across each dataset.


### PCA

This section plots the PCA for each dataset, clockwise from the top left:

1. `scDblFinder` singlet/doublet calls
2. `scrublet` singlet/doublet calls
3. `cxds` singlet/doublet calls 
4. Ground truth single/doublets
5. Consensus _call_ droplets are either "doublet" or "singlet"
6. Consensus _class_: droplets are either "doublet", "singlet", or "ambiguous"

For the first five panels, doublets are shown in black and singlets in light gray.


```{r, fig.width = 12, fig.height = 6}
doublet_df_list |>
  purrr::iwalk(
    \(df, dataset) {
      
      pc_color_columns <- c("scDblFinder prediction" = "scdbl_prediction",
                            "scublet prediction" = "scrublet_prediction",
                            "cxds prediction" = "cxds_prediction",
                            "Ground truth" = "ground_truth", 
                            "Consensus call" = "consensus_call")
      
      pc_plot_list <- pc_color_columns |> 
        purrr::imap(
          \(color_column, plot_title) {
            plot_pca_calls(
              df, 
              color_column = !!sym(color_column), 
              title = plot_title
            )}
        ) 
      
      # note that the list name isn't used here
      pc_plot_list$metrics <- plot_pca_metrics(
        df,
        confusion_call, 
        metric_colors = confusion_colors
      )
      
      patchwork::wrap_plots(pc_plot_list) +
        plot_annotation(
            glue::glue("PCA for {dataset}"), 
            theme = theme(plot.title = element_text(size = 16))) + 
        plot_layout(guides = "collect")
    }
  )
```


### Performance metrics 

This section calculates a confusion matrix and associated statistics on the consensus classes. 

```{r}
metric_df <- doublet_df_list |>
  purrr::imap( 
    \(df, dataset) {
        print(glue::glue("======================== {dataset} ========================"))
      
        cat("Table of consensus calls:")
        print(table(df$consensus_class))
        
        cat("\n\n")
        
        confusion_result <- caret::confusionMatrix(
          # truth should be first
          table(
            "Truth" = df$ground_truth,
            "Consensus prediction" = df$consensus_call
          ), 
          positive = "doublet"
        ) 
        
        print(confusion_result)
        
        # Extract information we want to present later in a table
        tibble::tibble(
          "Dataset name" = dataset,
          "Kappa" = round(confusion_result$overall["Kappa"], 3), 
          "Balanced accuracy" = round(confusion_result$byClass["Balanced Accuracy"], 3)
        )
    }
  ) |>
  dplyr::bind_rows()
```



## Conclusions

Overall, methods do not have substantial overlap with each other. 
They each tend to detect different sets of doublets, leading to fairly small sets of consensus doublets. 
Further, the consensus doublets called by all three methods have some, but not substantial, overlap with the ground truth. 

For three out of four datasets, `scDblFinder` predicts a much larger number of doublets compared to other methods. 

Based on the PCAs, it additionally looks like there are many more false negatives in the consensus prediction that `cxds` appears to capture but other methods do not.

The table below summarizes performance of the "consensus caller". 
Note that, in the [benchmarking paper these datasets were originally analyzed in](https://doi.org/10.1016/j.cels.2020.11.008), `hm-6k` was observed to be one of the "easiest" datasets to classify across methods.  
Consistent with that observation, it has the highest `kappa` value here.

```{r}
metric_df
```


## Session Info

```{r session info}
# record the versions of the packages used in this analysis and other environment information
sessionInfo()
```
