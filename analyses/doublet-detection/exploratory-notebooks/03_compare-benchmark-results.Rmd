---
title: "Comparison among doublet predictions on benchmarking datasets"
author: Stephanie J. Spielman
date: "`r Sys.Date()`"
output: 
  html_notebook:
    toc: true
    toc_depth: 4
    code_folding: hide
---

This notebook compares doublet results calculated on benchmarking datasets to one another, with the primary goal of addressing these questions:

1. Do methods tend to predict overlapping or distinct sets of doublets on the same dataset?
2. Is the consensus doublet call across methods predictive of the true doublet status?
Here, the "consensus doublets" are those droplets which all methods identify as doublets.

There are several items to bear in mind when interpreting these results:

- The ground truth calls themselves to which we are comparing consensus calls may not be entirely accurate, since they were also computationally identified generally with demultiplexing algorithms. 
- `cxds`, as we are using it, does not have a specific threshold for calling droplets. 
By contrast, both `scrublet` and `scDblFinder` identify a threshold based on the given dataset they are processing. 
This notebook used a doublet threshold of `>=0.5` for `cxds`, which may not be universally suitable (though choosing a universally suitable threshold is not easy either!).

## Setup

### Packages


```{r packages}
suppressPackageStartupMessages({
  library(SingleCellExperiment)
  library(ggplot2)
  library(patchwork)
  library(caret)
  library(UpSetR)
})

theme_set(theme_bw())

# define threshold used to call cxds
cxds_threshold <- 0.5
```

### Paths


```{r base paths}
module_base <- rprojroot::find_root(rprojroot::is_renv_project)
data_dir <- file.path(module_base, "scratch", "benchmark-datasets")
result_dir <- file.path(module_base, "results", "benchmark-results")
```

### Functions

```{r}
plot_pca_calls <- function(df, 
                           color_column, 
                           pred_column,
                           title) {
  # Plot PCs colored by singlet/doublet, showing doublets on top
  # df is expected to contain columns PC1, PC2, `color_column`, and `pred_column`. These should _not_ be provided as strings
  ggplot(df) + 
    aes(x = PC1, 
        y = PC2, 
        color = {{color_column}}) +
  geom_point(
    size = 0.75, 
    alpha = 0.6
  ) +
  scale_color_manual(name = "", values = c("black", "gray80")) + 
  geom_point(
    data = dplyr::filter(df, {{color_column}} == "doublet"), 
    color = "black",
    size = 0.75
  ) +
  ggtitle(title) 
}

plot_pca_metrics <- function(df, color_column, metric_colors) {
  # Plot PCs colored by performance metric, showing false calls on top
  # metric_colors is a named vector of colors used for coloring tp/tn/fp/fn
  # df is expected to contain columns PC1, PC2, and `color_column`. This should _not_ be provided as a string.
  ggplot(df) + 
    aes(x = PC1, 
        y = PC2, 
        color = {{color_column}}) +
  geom_point(
    size = 0.75, 
    alpha = 0.6
  ) + 
  geom_point(
    data = dplyr::filter(df, {{color_column}} %in% c("fp", "fn")), 
    size = 0.75
  ) +
  scale_color_manual(name = "Call type", values = metric_colors) +
  ggtitle("Consensus call metrics")
}
```


## Read and prepare input data

First, we'll read in and combine doublet results into a list of data frames for each dataset.
We'll also create new columns for each dataset:

- `consensus_call`, which will be "doublet" if _all_ methods predict "doublet," and "singlet" otherwise
- `call_type`, which will classify the consensus call as one of "tp", "tn", "fp", or "fn" (true/false positive/negative) 

```{r paths}
# find all dataset names to process:
dataset_names <- list.files(result_dir, pattern = "*_scrublet.tsv") |>
  stringr::str_remove("_scrublet.tsv")
```

```{r read_data}
# used in PCA plots
confusion_colors <- c(
  "tp" = "lightblue",
  "tn" = "pink",
  "fp" = "blue",
  "fn" = "firebrick2"
)

# Read in data for analysis
doublet_df_list <- dataset_names |>
  purrr::map(
    \(dataset) {
      
      scdbl_tsv <- file.path(result_dir, glue::glue("{dataset}_scdblfinder.tsv"))
      scrub_tsv <- file.path(result_dir, glue::glue("{dataset}_scrublet.tsv"))
      sce_file <- file.path(data_dir, dataset, glue::glue("{dataset}_sce.rds"))
      
      scdbl_df <- scdbl_tsv |>
        readr::read_tsv(show_col_types = FALSE) |>
        dplyr::select(
          barcodes,
          cxds_score, 
          scdbl_score = score, 
          scdbl_prediction  = class
        ) |>
        # add cxds calls at `cxds_threshold` threshold
        dplyr::mutate(
          cxds_prediction = dplyr::if_else(
            cxds_score >= cxds_threshold,
            "doublet",
            "singlet"
          )
        ) 
      
      scrub_df <- readr::read_tsv(scrub_tsv, show_col_types = FALSE) 

      # grab ground truth and PCA coordinates
      sce <- readr::read_rds(sce_file)
      dataset_df <- scuttle::makePerCellDF(sce, use.dimred = "PCA") |>
        tibble::rownames_to_column(var = "barcodes") |>
        dplyr::select(barcodes,
                      ground_truth = ground_truth_doublets, 
                      PC1 = PCA.1, 
                      PC2 = PCA.2) |> 
        dplyr::left_join(
          scrub_df, 
          by = "barcodes"
        ) |>
        dplyr::left_join(
          scdbl_df, 
          by = "barcodes"
        ) 
      
      # Add a consensus call column
      dataset_df <- dataset_df |>
        dplyr::rowwise() |>
        dplyr::mutate(consensus_call = dplyr::if_else(
          all(
            c(scdbl_prediction, scrublet_prediction, cxds_prediction) == "doublet"
          ),
          "doublet", 
          "singlet"
        )) |>
        dplyr::mutate(
          call_type = dplyr::case_when(
            consensus_call == "doublet" && ground_truth == "doublet" ~ "tp",
            consensus_call == "singlet" && ground_truth == "singlet" ~ "tn",
            consensus_call == "doublet" && ground_truth == "singlet" ~ "fp",
            consensus_call == "singlet" && ground_truth == "doublet" ~ "fn"
          )
        )
      
      return(dataset_df)
    }
  ) |> 
  purrr::set_names(dataset_names)
```




## Upset plots

This section contains upset plots that show overlap across doublet calls from each method, displayed for each dataset.

```{r}
upset_list <- doublet_df_list |>
  purrr::iwalk(
    \(df, dataset) {
      
      doublet_barcodes <- list(
        "scDblFinder" = df$barcodes[df$scdbl_prediction == "doublet"],
        "scrublet"    = df$barcodes[df$scrublet_prediction == "doublet"],
        "cxds"        = df$barcodes[df$cxds_prediction == "doublet"]
      )
      
      UpSetR::upset(fromList(doublet_barcodes), order.by = "freq") |> print()
      grid::grid.text( # plot title
        dataset,
        x = 0.65, 
        y = 0.95, 
        gp = grid::gpar(fontsize=16)
      ) 

    }
  )

```



## Evaluating consensus performance

This section visualizes and evaluates the consensus doublet calls across each dataset.


### PCA

This section plots the PCA for each dataset, clockwise from the top left:

1. `scDblFinder` singlet/doublet calls. 
2. `scrublet` singlet/doublet calls
3. `cxds` singlet/doublet calls 
4. Ground truth single/doublets
5. Consensus singlet/doublet calls
6. Points are colored based on comparing the consensus call to the ground truth as one of:
    - true positive (`tp`), true negative (`tn`), false positive (`fp`), false negative (`fn`)

For the first five panels, doublets are shown in black and singlets in light gray.


```{r, fig.width = 12, fig.height = 6}
doublet_df_list |>
  purrr::iwalk(
    \(df, dataset) {
      
      # Top row: methods themselves ---
      p1 <- plot_pca_calls(
        df, 
        color_column = scdbl_prediction, 
        title = "scDblFinder prediction"
      )
      
      p2 <- plot_pca_calls(
        df, 
        color_column = scrublet_prediction, 
        title = "scrublet prediction"
      )
                
      p3 <- plot_pca_calls(
        df, 
        color_column = cxds_prediction, 
        title = "cxds prediction"
      )
      
      # Bottom row: consensus  --
      p4 <- plot_pca_calls(
        df, 
        color_column = ground_truth, 
        title = "Ground truth"
      )
      
      # Second, consensus call
      p5 <- plot_pca_calls(
        df, 
        color_column = consensus_call, 
        title = "Consensus call"
      )
      
      # Third, call type
      p6 <- plot_pca_metrics(
        df,
        call_type, 
        metric_colors = confusion_colors
      )

      # combine and plot
      plot( 
        (p1 + p2 + p3) / (p4 + p5 + p6) + 
          plot_annotation(
            glue::glue("PCA for {dataset}"), 
            theme = theme(plot.title = element_text(size = 16))) + 
          plot_layout(guides = "collect"))
    }
  )
```


### Performance metrics 

This section calculates a confusion matrix and associated statistics on the consensus calls. 

```{r}
metric_df <- doublet_df_list |>
  purrr::imap( 
    \(df, dataset) {
        print(glue::glue("======================== {dataset} ========================"))
      
        cat("Table of consensus calls:")
        print(table(df$consensus_call))
        
        cat("\n\n")
        
        confusion_result <- caret::confusionMatrix(
          # truth should be first
          table(
            "Truth" = df$ground_truth,
            "Consensus prediction" = df$consensus_call
          ), 
          positive = "doublet"
        ) 
        
        print(confusion_result)
        
        # Extract information we want to present later in a table
        tibble::tibble(
          "Dataset name" = dataset,
          "Kappa" = round(confusion_result$overall["Kappa"], 3), 
          "Balanced accuracy" = round(confusion_result$byClass["Balanced Accuracy"], 3)
        )
    }
  ) |>
  dplyr::bind_rows()
```



## Conclusions

Overall, methods do not have substantial overlap with each other. 
They each tend to detect different sets of doublets, leading to fairly small sets of consensus doublets. 
Further, the consensus doublets called by all three methods have some, but not substantial, overlap with the ground truth. 

For three out of four datasets, `scDblFinder` predicts a much larger number of doublets compared to other methods. 
For `pdx-MULTI`, however, `cxds` predicts a much larger number of droplets.

The table below summarizes performance of the "consensus caller". 
Note that, in the [benchmarking paper these datasets were originally analyzed in](https://doi.org/10.1016/j.cels.2020.11.008), `hm-6k` was observed to be one of the "easiest" datasets to classify across methods.  
Consistent with that observation, it has the highest `kappa` value here, although it is still fairly low - though not as low as the other methods, which are very close to 0. 

```{r}
metric_df
```


## Session Info

```{r session info}
# record the versions of the packages used in this analysis and other environment information
sessionInfo()
```
